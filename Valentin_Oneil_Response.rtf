{\rtf1\ansi\ansicpg1252\cocoartf1504\cocoasubrtf810
{\fonttbl\f0\froman\fcharset0 TimesNewRomanPSMT;}
{\colortbl;\red255\green255\blue255;\red17\green17\blue17;}
{\*\expandedcolortbl;;\csgenericrgb\c6667\c6667\c6667;}
\margl1440\margr1440\vieww10800\viewh8400\viewkind0
\deftab720
\pard\pardeftab720\ri720\partightenfactor0

\f0\fs24 \cf0 David Valentin\
Statistical Learning\
March 8, 2017\
\
\pard\pardeftab720\ri720\qc\partightenfactor0

\b \cf0 \ul \ulc0 Weapons of Math Destruction Response\
\pard\pardeftab720\ri720\partightenfactor0

\b0 \cf0 \ulnone \
\pard\pardeftab720\ri720\sl360\slmult1\partightenfactor0
\cf0 	O\'92Neil discuses the nature of machine learning algorithms and how the inferences and more importantly the decision made by these algorithms can be hugely detrimental and can cause a chain effect. Algorithms measure the likelihood that a criminal defendant is likely to return back into prison, and that score is given to the judge in sentencing and for release in parole. There exists a correlation between if you have a higher recidivism risk, then often you are sentenced in prison longer, which causes a snowball affect as the longer you spend in jail then you become more isolated from your community. \
	O\'92Neil discussed the data that was used in these algorithms and highlighted the biases in the LSIR, and how they act as proxies for racism and classism. Much more policing in neighborhoods that are socioeconomically disenfranchised, and the data coming in from the police interactions is inherently biased. \
	She points out that because the score does not illustrate the process in which the data is collected, and points out the illusion that since the data is purely quantitative as a score, there are fewer questions brought against it. \
\pard\pardeftab720\ri720\sl360\slmult1\partightenfactor0
\cf2 	In addition, O\'92Neil discusses an example of building a machine-learning algorithm for tech recruitment, and describes how it is built to sort through resumes, but she notes that most machine learning algorithms could face an inherent designer bias since most software engineers are male as they could be screening for the wrong variables. \
\pard\pardeftab720\ri720\sl360\slmult1\partightenfactor0
\cf0 	O\'92Neil points out how teachers are evaluated based off students\'92 grades, and the inherent biases in scoring student scoring. The interviewer also notes that once teachers started being evaluated by student scores then education institutions started manipulating standardized test scores. Moreover, O\'92Neil points out that education costs have risen due to the standardized practices and money poured into both gaming entrance into universities and maintaining the admissions yields. \
}