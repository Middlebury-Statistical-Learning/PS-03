      While the algorithm used to ‘rate’ crime recidivism accurately depicts a possible correlation between certain factors and the chance one may repeat a crime, the algorithm itself may contribute to increased crime recidivism, as those who are said to be more dangerous and more likely to commit crime, are given more jail time and therefore have fewer resources to avoid crime one released from prison. Beyond the circular and self-fulfilling nature of the algorithm, the actual inputs are flawed, as many are proxies for race or socio-economic level, which are often used as justification for more police in an area, which inherently leads to more arrests. While the algorithm can accurately track the correlation between certain points on the graph, if the points being fed in are flawed, the entire algorithm will be flawed.      The tech company thought experiment brought to a light a similar issue that the crime recidivism algorithm did; these algorithms can often be self-fulfilling if listened to too religiously, and if one continues to only hire men, men will likely be the only one’s to succeed. Beyond that idea, we also see that the algorithm could be identifying a problem of gender injustice, but instead of that problem being realized, it is instead used as a ‘mathematical’ justification for no longer hiring women. The data must be interpreted correctly, allowing for the realization of causation. Instead, the algorithms are often only used to find the answer of ‘what happened,’ and not ‘why did this happen?’      The example given concerning the algorithm that grades a teacher’s values added is inherently flawed as the algorithm both fails to find a good metric by which to grade teachers (tests are an inherently flawed method), and the method of deciding whether a students tests are sufficient or not is also inherently flawed as it places far too much responsibility on the teacher, and misses the possibility of previous teachers. Beyond this, and more related to the math, the idea of ‘noise’ is completely ignored, as the entire score of a teacher is almost completely based off of the noise of the model; slight discrepancies between two scores from the same child. And what’s more, the model itself graded the same teacher in the same year similarly on 25% of the time, showing the clear incompetence of the model.