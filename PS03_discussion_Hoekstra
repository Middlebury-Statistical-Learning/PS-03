- Explain in three paragraphs Cathy O’Neil’s argument of how supposedly objective mathematical/algorithmic models reinforce inequality in the context of 1) crime recidivism, 2) the thought experiment of hiring in tech firms and 3) teacher evaluations.

    With data it’s really easy to think you’re being objective when you might be putting biases into the work. In my bio classes, this means messing around with the data until we get a more desirable result. I did not realize until I listened to Cathy O’ Neil’s interview that algorithm misuse was this widespread. With crime recidivism, the theory is that a person’s risk of re-entering the system impacts their length of jail time. More risk leads to a longer sentence. However, some of the factors are out of the person’s control. If they are from a crime- filled area or a parent has been in jail their risk is higher, but that could be a proxy for labeling them as poor. Poorer people are than at a disadvantage compared to their already better-off peers. Since longer jail times can make it harder to re-enter society, this practice can reinforce inequality.
    With tech firms, the argument can be boiled down to “if it ain’t broke, don’t fix it”. Men tend to outperform women in tech firms, which can then be used to justify hiring more men. However, there are societal and systemic reasons that could be holding women back professionally. By continuing to hire mostly men, tech firms do not do anything to fix those inequalities; instead, they make it worse. This can also be seen in hiring only those who graduate from certain schools; while those graduates are definitely qualified, they ignore other qualified applicants.
    Many studies have shown that test scores reflect a person’s income bracket. Wealthier families are better fed and have more resources to help a child academically. If a student is poor they probably won’t have access to healthy food, tutors, or well-run schools. Therefore, grading a teacher based on their students’ performances on standardize tests really grades them on the wealth of their students. More recent models are more complicated than that, but they fail to take the nuances of teaching into consideration. This frustrated me immensely in high school, as I felt I was being taught for a test and not for the sake of learning. The teachers couldn’t do anything about it though, as their job security was based on me performing well on the end of year exams. My senior year, Pennsylvania switched tests to one that covered more subjects. The same test would be administered to a student regardless of whether they took AP biology or remedial biology. The teacher would then be evaluated on the score, which severely docked those working with students who needed extra assistance. Algorithms are good but they are not a cure all.