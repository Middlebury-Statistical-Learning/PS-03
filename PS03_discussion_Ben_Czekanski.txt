1) Crime Recidivism:	When judges are making decisions about sentencing they are given a rating of the criminal’s likelihood of becoming a repeat offender. In the podcast, it sounded like there is a percentage chance that is then grouped into three categories, which is absurd. Beyond that, the severity of the sentence that the judge hands down often affects the criminal’s ability to recover after leaving jail, and to become a “productive citizen”. In this way the algorithm is somewhat self-predicting, a high rating leads to a longer sentence which in turn leads to a higher chance of committing a crime again. This feedback loop is dangerous and not fair to those involved.2) Tech Firms:	Tech firms are often started by men, who initially hire other men to work with them. As the company grows, these first employees are the ones who attain leadership roles, as they are the longest tenured employees. Being tech firms, these companies try to use algorithms to determine which employees are good candidates for management. The algorithms that are discussed in the podcast use the companies’ data about previous leaders and how they grew to their positions to identify the next leaders. The algorithm does as it is told, and gives management employees who are similar to them. However, no women are selected by the algorithm because there is no history of women growing into management for the algorithm to look at. The algorithm simply sees the past and tries to predict based on that data, but when the data is flawed the results given by the algorithm will also be flawed.3) Teacher Evaluations:	Teacher evaluations are an attempt use a single number to evaluate performance in a very difficult job, one that cannot really be quantified. In the New York example, the algorithm was not good enough to consistently give teachers similar scores in the same year if they taught different grades. The teachers also were not told what went into the algorithm, so they were not aware of what parts of their teaching style needed work. Teacher evaluations like this are primarily used in public schools where there is need for some mechanism to determine which teachers are and are not good at their jobs. However, the inconsistent and opaque nature of the New York example given in the podcast is a failure, both to determine which teachers are failing, and to give teachers feedback on their performance.