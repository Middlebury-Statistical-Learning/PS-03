	Cathy O’Neil looks at weapons of math destruction, meaning mathematical models that through some bias disproportionately hurt different communities.  Math is viewed as a very scientific way of measuring indexes and with the increase in big data, more modeling can take place.  O’Neil warns against these models because a lot of time they increase inequality through unforeseen ways, like recidivism risk scores.  Recidivism risk scores are given to people entering jail and the likelihood a given criminal will return.  They are rated as low, medium or high risk for return to prison and this information is given during sentencing to the judge.  There is a feedback loop that once a person is put in jail for a long time, they have fewer connections on the outside and less money, which makes them more likely to return to jail.  Cathy O’Neil believes that jail is not a productive form of rehabilitation and a longer sentence actually hurts the prisoners.  These scores are built on interaction with police and surveys given to prisoners to build a logistic model.  The model also includes any small interactions with police, including certain crimes that disproportionately affect minorities.  Also, the survey questions target minorities with questions looking at high crime areas and family members in jail.  Using things like zip code gets around using race as a variable, but it is more accurate.  
	The thought experiment for hiring in tech firms is through using a machine learning algorithm to sort through resumes.  Using previous employees as data points, the company would build a model on those characteristics and whether these employees succeeded.  This model would look for people who look like certain success stories in the company.  In this example, no women make it through the filter.  The algorithm shows that women do not succeed in the company, possibly due to the culture. O’Neil objects to major decisions being made by rather simple models.
	The teacher value added model has some discrimination issues but the scores are not very meaningful.  The scores are not very consistent.  This is an attempt to measure the ability of teachers and is typically used to fire teachers under certain mandates.  The idea is to get rid of bad teachers who are hurting education, but the solution does not solve the problem.  The initial models measured the teacher’s performance on the number of students who were proficient in a given subject by the end of the year.  This disproportionately hurt teachers of low income students who were not proficient the year before and likely were not proficient in that given year either.  The new model looks at given the test score in the previous year and is given an expected score for the current year.  The new value added score is the sum of the differences between what the students get versus what they were supposed to get.  The scoring system sounds good, but it is not consistent enough.  The source code was not given to O’Neil or even the department of education.  Since the New York Times used the Freedom of Information Act to obtain the results to shame poorly performing teachers, another teacher was able to use the duplicate points of teachers to show that the result is a uniform distribution meaning that the model does not really do anything.  The scores are not accurate enough to fire people over.  